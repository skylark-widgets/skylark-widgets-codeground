{"version":3,"sources":["mode/sass/sass.js"],"names":["define","CodeMirror","defineMode","config","tokenRegexp","words","RegExp","join","urlTokens","stream","state","ch","peek","next","tokenizer","tokenBase","eatSpace","buildStringTokenizer","comment","indentation","multiLine","sol","skipTo","skipToEnd","quote","greedy","stringTokenizer","nextChar","peekChar","previousChar","string","charAt","pos","endingString","buildInterpolationTokenizer","currentTokenizer","indent","indentCount","lastScopeOffset","scopes","offset","currentOffset","indentUnit","unshift","dedent","length","shift","match","cursorHalf","keywordsRegexp","eatWhile","opRegexp","pseudoElementsRegexp","tokenLexer","style","current","startOfToken","withCurrentIndent","newScopes","i","scope","push","keywords","operators","startState","type","definedVars","definedMixins","token","lastToken","content","defineMIME"],"mappings":";;;;;;;AAGAA,QAAQ,eAAgB,SAASC,GACjC,YAEAA,GAAWC,WAAW,OAAQ,SAASC,GACrC,QAASC,GAAYC,GACnB,MAAO,IAAIC,QAAO,IAAMD,EAAME,KAAK,MAYrC,QAASC,GAAUC,EAAQC,GACzB,GAAIC,GAAKF,EAAOG,MAEhB,OAAW,MAAPD,GACFF,EAAOI,OACPH,EAAMI,UAAYC,EACX,YACS,MAAPJ,GACTF,EAAOI,OACPJ,EAAOO,WAEA,YACS,MAAPL,GAAqB,MAAPA,GACvBD,EAAMI,UAAYG,EAAqBR,EAAOI,QACvC,WAEPH,EAAMI,UAAYG,EAAqB,KAAK,GACrC,UAGX,QAASC,GAAQC,EAAaC,GAC5B,MAAO,UAASX,EAAQC,GACtB,MAAID,GAAOY,OAASZ,EAAOU,eAAiBA,GAC1CT,EAAMI,UAAYC,EACXA,EAAUN,EAAQC,KAGvBU,GAAaX,EAAOa,OAAO,OAC7Bb,EAAOI,OACPJ,EAAOI,OACPH,EAAMI,UAAYC,GAElBN,EAAOc,YAGF,YAIX,QAASN,GAAqBO,EAAOC,GAGnC,QAASC,GAAgBjB,EAAQC,GAC/B,GAAIiB,GAAWlB,EAAOI,OAClBe,EAAWnB,EAAOG,OAClBiB,EAAepB,EAAOqB,OAAOC,OAAOtB,EAAOuB,IAAI,GAE/CC,EAA8B,OAAbN,GAAqBC,IAAaJ,GAAWG,IAAaH,GAA0B,OAAjBK,CAExF,OAAII,IACEN,IAAaH,GAASC,GAAUhB,EAAOI,OAC3CH,EAAMI,UAAYC,EACX,UACe,MAAbY,GAAiC,MAAbC,GAC7BlB,EAAMI,UAAYoB,EAA4BR,GAC9CjB,EAAOI,OACA,YAEA,SAIX,MAtBc,OAAVY,IAAkBA,GAAS,GAsBxBC,EAGT,QAASQ,GAA4BC,GACnC,MAAO,UAAS1B,EAAQC,GACtB,MAAsB,MAAlBD,EAAOG,QACTH,EAAOI,OACPH,EAAMI,UAAYqB,EACX,YAEApB,EAAUN,EAAQC,IAK/B,QAAS0B,GAAO1B,GACd,GAAyB,GAArBA,EAAM2B,YAAkB,CAC1B3B,EAAM2B,aACN,IAAIC,GAAkB5B,EAAM6B,OAAO,GAAGC,OAClCC,EAAgBH,EAAkBnC,EAAOuC,UAC7ChC,GAAM6B,OAAOI,SAAUH,OAAOC,KAIlC,QAASG,GAAOlC,GACa,GAAvBA,EAAM6B,OAAOM,QAEjBnC,EAAM6B,OAAOO,QAGf,QAAS/B,GAAUN,EAAQC,GACzB,GAAIC,GAAKF,EAAOG,MAGhB,IAAIH,EAAOsC,MAAM,MAEf,MADArC,GAAMI,UAAYI,EAAQT,EAAOU,eAAe,GACzCT,EAAMI,UAAUL,EAAQC,EAEjC,IAAID,EAAOsC,MAAM,MAEf,MADArC,GAAMI,UAAYI,EAAQT,EAAOU,eAAe,GACzCT,EAAMI,UAAUL,EAAQC,EAIjC,IAAID,EAAOsC,MAAM,MAEf,MADArC,GAAMI,UAAYoB,EAA4BnB,GACvC,UAIT,IAAW,MAAPJ,GAAqB,MAAPA,EAGhB,MAFAF,GAAOI,OACPH,EAAMI,UAAYG,EAAqBN,GAChC,QAGT,IAAID,EAAMsC,WAmHN,CAEF,GAAW,MAAPrC,IACFF,EAAOI,OAEHJ,EAAOsC,MAAM,kCAIf,MAHItC,GAAOG,SACTF,EAAMsC,WAAa,GAEd,QAKX,IAAIvC,EAAOsC,MAAM,eAIf,MAHItC,GAAOG,SACTF,EAAMsC,WAAa,GAEd,QAIT,IAAIvC,EAAOsC,MAAM,iBAIf,MAHItC,GAAOG,SACTF,EAAMsC,WAAa,GAEd,MAGT,IAAIvC,EAAOsC,MAAME,GAIf,MAHIxC,GAAOG,SACTF,EAAMsC,WAAa,GAEd,SAGT,IAAIvC,EAAOsC,MAAM,SAA6B,MAAlBtC,EAAOG,OAKjC,MAJAF,GAAMI,UAAYN,EACdC,EAAOG,SACTF,EAAMsC,WAAa,GAEd,MAIT,IAAW,MAAPrC,EAMF,MALAF,GAAOI,OACPJ,EAAOyC,SAAS,SACZzC,EAAOG,SACTF,EAAMsC,WAAa,GAEd,YAIT,IAAW,MAAPrC,EAKF,MAJAF,GAAOI,OACHJ,EAAOG,SACTF,EAAMsC,WAAa,GAEdvC,EAAOsC,MAAM,UAAY,UAAW,UAG7C,IAAItC,EAAOsC,MAAMI,GAIf,MAHI1C,GAAOG,SACTF,EAAMsC,WAAa,GAEd,UAIT,IAAIvC,EAAOyC,SAAS,SAIlB,MAHIzC,GAAOG,SACTF,EAAMsC,WAAa,GAEd,WAIT,KAAIvC,EAAOG,OAET,MADAF,GAAMsC,WAAa,EACZ,SApMU,CAInB,GAAW,MAAPrC,EAAY,CAEd,GADAF,EAAOI,OACHJ,EAAOsC,MAAM,WAEf,MADAX,GAAO1B,GACA,MACF,IAAsB,MAAlBD,EAAOG,OAEhB,MADAwB,GAAO1B,GACA,OAIX,GAAW,MAAPC,EAAY,CAGd,GAFAF,EAAOI,OAEHJ,EAAOsC,MAAM,WAEf,MADAX,GAAO1B,GACA,MAET,IAAsB,MAAlBD,EAAOG,OAET,MADAwB,GAAO1B,GACA,OAKX,GAAW,MAAPC,EAGF,MAFAF,GAAOI,OACPJ,EAAOyC,SAAS,SACT,YAIT,IAAIzC,EAAOsC,MAAM,eACf,MAAO,QAGT,IAAItC,EAAOsC,MAAM,iBACf,MAAO,MAET,IAAItC,EAAOsC,MAAME,GACf,MAAO,SAET,IAAIxC,EAAOsC,MAAM,SAA6B,MAAlBtC,EAAOG,OAEjC,MADAF,GAAMI,UAAYN,EACX,MAGT,IAAW,MAAPG,GAEEF,EAAOsC,MAAM,YAEf,MADAX,GAAO1B,GACA,MAIX,IAAW,MAAPC,GAEEF,EAAOsC,MAAM,aACf,MAAO,YAaX,IATU,MAAPpC,GACEF,EAAOsC,MAAM,aACVtC,EAAOsC,MAAM,YACfH,EAAOlC,IAMTD,EAAOsC,MAAM,2DAEf,MADAX,GAAO1B,GACA,MAIT,IAAW,MAAPC,EAGF,MAFAF,GAAOI,OACPJ,EAAOyC,SAAS,SACT,MAGT,IAAIzC,EAAOyC,SAAS,SAClB,MAAGzC,GAAOsC,MAAM,wBAAuB,GAC9B,WAEDtC,EAAOsC,MAAM,OAAM,IACzBX,EAAO1B,GACPA,EAAMsC,WAAa,EACZ,QAEDvC,EAAOsC,MAAM,OAAM,GAClB,QAGPX,EAAO1B,GACA,OAIX,IAAU,MAAPC,EACD,MAAIF,GAAOsC,MAAMK,GACR,WAET3C,EAAOI,OACPH,EAAMsC,WAAW,EACV,YA0FX,MAAIvC,GAAOsC,MAAMI,GACR,YAIT1C,EAAOI,OACA,MAGT,QAASwC,GAAW5C,EAAQC,GACtBD,EAAOY,QAAOX,EAAM2B,YAAc,EACtC,IAAIiB,GAAQ5C,EAAMI,UAAUL,EAAQC,GAChC6C,EAAU9C,EAAO8C,SAMrB,IAJgB,YAAZA,GAAqC,MAAZA,GAC3BX,EAAOlC,GAGK,OAAV4C,EAAgB,CAOlB,IAAK,GANDE,GAAe/C,EAAOuB,IAAMuB,EAAQV,OAEpCY,EAAoBD,EAAgBrD,EAAOuC,WAAahC,EAAM2B,YAE9DqB,KAEKC,EAAI,EAAGA,EAAIjD,EAAM6B,OAAOM,OAAQc,IAAK,CAC5C,GAAIC,GAAQlD,EAAM6B,OAAOoB,EAErBC,GAAMpB,QAAUiB,GAClBC,EAAUG,KAAKD,GAGnBlD,EAAM6B,OAASmB,EAIjB,MAAOJ,GA5WT,GAAIQ,IAAY,OAAQ,QAAS,OAAQ,QACrCb,EAAiB,GAAI3C,QAAO,IAAMwD,EAASvD,KAAK,MAEhDwD,GAAa,MAAO,MAAO,IAAK,IAAK,IAAK,KAAM,KAAM,KAAM,MAAO,IACtD,OAAQ,IAAK,MAAO,IAAK,MAAO,KAAM,MAAO,IAAI,MAAM,MAAM,KAC1EZ,EAAW/C,EAAY2D,GAEvBX,EAAuB,sBAwW3B,QACEY,WAAY,WACV,OACElD,UAAWC,EACXwB,SAAUC,OAAQ,EAAGyB,KAAM,SAC3B5B,YAAa,EACbW,WAAY,EAEZkB,eACAC,mBAGJC,MAAO,SAAS3D,EAAQC,GACtB,GAAI4C,GAAQD,EAAW5C,EAAQC,EAI/B,OAFAA,GAAM2D,WAAcf,MAAOA,EAAOgB,QAAS7D,EAAO8C,WAE3CD,GAGTlB,OAAQ,SAAS1B,GACf,MAAOA,GAAM6B,OAAO,GAAGC,WAK7BvC,EAAWsE,WAAW,cAAe","file":"../../../mode/sass/sass.js","sourcesContent":["// CodeMirror, copyright (c) by Marijn Haverbeke and others\n// Distributed under an MIT license: http://codemirror.net/LICENSE\n\ndefine([\"../../Coder\"], function(CodeMirror) {\n\"use strict\";\n\nCodeMirror.defineMode(\"sass\", function(config) {\n  function tokenRegexp(words) {\n    return new RegExp(\"^\" + words.join(\"|\"));\n  }\n\n  var keywords = [\"true\", \"false\", \"null\", \"auto\"];\n  var keywordsRegexp = new RegExp(\"^\" + keywords.join(\"|\"));\n\n  var operators = [\"\\\\(\", \"\\\\)\", \"=\", \">\", \"<\", \"==\", \">=\", \"<=\", \"\\\\+\", \"-\",\n                   \"\\\\!=\", \"/\", \"\\\\*\", \"%\", \"and\", \"or\", \"not\", \";\",\"\\\\{\",\"\\\\}\",\":\"];\n  var opRegexp = tokenRegexp(operators);\n\n  var pseudoElementsRegexp = /^::?[a-zA-Z_][\\w\\-]*/;\n\n  function urlTokens(stream, state) {\n    var ch = stream.peek();\n\n    if (ch === \")\") {\n      stream.next();\n      state.tokenizer = tokenBase;\n      return \"operator\";\n    } else if (ch === \"(\") {\n      stream.next();\n      stream.eatSpace();\n\n      return \"operator\";\n    } else if (ch === \"'\" || ch === '\"') {\n      state.tokenizer = buildStringTokenizer(stream.next());\n      return \"string\";\n    } else {\n      state.tokenizer = buildStringTokenizer(\")\", false);\n      return \"string\";\n    }\n  }\n  function comment(indentation, multiLine) {\n    return function(stream, state) {\n      if (stream.sol() && stream.indentation() <= indentation) {\n        state.tokenizer = tokenBase;\n        return tokenBase(stream, state);\n      }\n\n      if (multiLine && stream.skipTo(\"*/\")) {\n        stream.next();\n        stream.next();\n        state.tokenizer = tokenBase;\n      } else {\n        stream.skipToEnd();\n      }\n\n      return \"comment\";\n    };\n  }\n\n  function buildStringTokenizer(quote, greedy) {\n    if (greedy == null) { greedy = true; }\n\n    function stringTokenizer(stream, state) {\n      var nextChar = stream.next();\n      var peekChar = stream.peek();\n      var previousChar = stream.string.charAt(stream.pos-2);\n\n      var endingString = ((nextChar !== \"\\\\\" && peekChar === quote) || (nextChar === quote && previousChar !== \"\\\\\"));\n\n      if (endingString) {\n        if (nextChar !== quote && greedy) { stream.next(); }\n        state.tokenizer = tokenBase;\n        return \"string\";\n      } else if (nextChar === \"#\" && peekChar === \"{\") {\n        state.tokenizer = buildInterpolationTokenizer(stringTokenizer);\n        stream.next();\n        return \"operator\";\n      } else {\n        return \"string\";\n      }\n    }\n\n    return stringTokenizer;\n  }\n\n  function buildInterpolationTokenizer(currentTokenizer) {\n    return function(stream, state) {\n      if (stream.peek() === \"}\") {\n        stream.next();\n        state.tokenizer = currentTokenizer;\n        return \"operator\";\n      } else {\n        return tokenBase(stream, state);\n      }\n    };\n  }\n\n  function indent(state) {\n    if (state.indentCount == 0) {\n      state.indentCount++;\n      var lastScopeOffset = state.scopes[0].offset;\n      var currentOffset = lastScopeOffset + config.indentUnit;\n      state.scopes.unshift({ offset:currentOffset });\n    }\n  }\n\n  function dedent(state) {\n    if (state.scopes.length == 1) return;\n\n    state.scopes.shift();\n  }\n\n  function tokenBase(stream, state) {\n    var ch = stream.peek();\n\n    // Comment\n    if (stream.match(\"/*\")) {\n      state.tokenizer = comment(stream.indentation(), true);\n      return state.tokenizer(stream, state);\n    }\n    if (stream.match(\"//\")) {\n      state.tokenizer = comment(stream.indentation(), false);\n      return state.tokenizer(stream, state);\n    }\n\n    // Interpolation\n    if (stream.match(\"#{\")) {\n      state.tokenizer = buildInterpolationTokenizer(tokenBase);\n      return \"operator\";\n    }\n\n    // Strings\n    if (ch === '\"' || ch === \"'\") {\n      stream.next();\n      state.tokenizer = buildStringTokenizer(ch);\n      return \"string\";\n    }\n\n    if(!state.cursorHalf){// state.cursorHalf === 0\n    // first half i.e. before : for key-value pairs\n    // including selectors\n\n      if (ch === \".\") {\n        stream.next();\n        if (stream.match(/^[\\w-]+/)) {\n          indent(state);\n          return \"atom\";\n        } else if (stream.peek() === \"#\") {\n          indent(state);\n          return \"atom\";\n        }\n      }\n\n      if (ch === \"#\") {\n        stream.next();\n        // ID selectors\n        if (stream.match(/^[\\w-]+/)) {\n          indent(state);\n          return \"atom\";\n        }\n        if (stream.peek() === \"#\") {\n          indent(state);\n          return \"atom\";\n        }\n      }\n\n      // Variables\n      if (ch === \"$\") {\n        stream.next();\n        stream.eatWhile(/[\\w-]/);\n        return \"variable-2\";\n      }\n\n      // Numbers\n      if (stream.match(/^-?[0-9\\.]+/))\n        return \"number\";\n\n      // Units\n      if (stream.match(/^(px|em|in)\\b/))\n        return \"unit\";\n\n      if (stream.match(keywordsRegexp))\n        return \"keyword\";\n\n      if (stream.match(/^url/) && stream.peek() === \"(\") {\n        state.tokenizer = urlTokens;\n        return \"atom\";\n      }\n\n      if (ch === \"=\") {\n        // Match shortcut mixin definition\n        if (stream.match(/^=[\\w-]+/)) {\n          indent(state);\n          return \"meta\";\n        }\n      }\n\n      if (ch === \"+\") {\n        // Match shortcut mixin definition\n        if (stream.match(/^\\+[\\w-]+/)){\n          return \"variable-3\";\n        }\n      }\n\n      if(ch === \"@\"){\n        if(stream.match(/@extend/)){\n          if(!stream.match(/\\s*[\\w]/))\n            dedent(state);\n        }\n      }\n\n\n      // Indent Directives\n      if (stream.match(/^@(else if|if|media|else|for|each|while|mixin|function)/)) {\n        indent(state);\n        return \"meta\";\n      }\n\n      // Other Directives\n      if (ch === \"@\") {\n        stream.next();\n        stream.eatWhile(/[\\w-]/);\n        return \"meta\";\n      }\n\n      if (stream.eatWhile(/[\\w-]/)){\n        if(stream.match(/ *: *[\\w-\\+\\$#!\\(\"']/,false)){\n          return \"property\";\n        }\n        else if(stream.match(/ *:/,false)){\n          indent(state);\n          state.cursorHalf = 1;\n          return \"atom\";\n        }\n        else if(stream.match(/ *,/,false)){\n          return \"atom\";\n        }\n        else{\n          indent(state);\n          return \"atom\";\n        }\n      }\n\n      if(ch === \":\"){\n        if (stream.match(pseudoElementsRegexp)){ // could be a pseudo-element\n          return \"keyword\";\n        }\n        stream.next();\n        state.cursorHalf=1;\n        return \"operator\";\n      }\n\n    } // cursorHalf===0 ends here\n    else{\n\n      if (ch === \"#\") {\n        stream.next();\n        // Hex numbers\n        if (stream.match(/[0-9a-fA-F]{6}|[0-9a-fA-F]{3}/)){\n          if(!stream.peek()){\n            state.cursorHalf = 0;\n          }\n          return \"number\";\n        }\n      }\n\n      // Numbers\n      if (stream.match(/^-?[0-9\\.]+/)){\n        if(!stream.peek()){\n          state.cursorHalf = 0;\n        }\n        return \"number\";\n      }\n\n      // Units\n      if (stream.match(/^(px|em|in)\\b/)){\n        if(!stream.peek()){\n          state.cursorHalf = 0;\n        }\n        return \"unit\";\n      }\n\n      if (stream.match(keywordsRegexp)){\n        if(!stream.peek()){\n          state.cursorHalf = 0;\n        }\n        return \"keyword\";\n      }\n\n      if (stream.match(/^url/) && stream.peek() === \"(\") {\n        state.tokenizer = urlTokens;\n        if(!stream.peek()){\n          state.cursorHalf = 0;\n        }\n        return \"atom\";\n      }\n\n      // Variables\n      if (ch === \"$\") {\n        stream.next();\n        stream.eatWhile(/[\\w-]/);\n        if(!stream.peek()){\n          state.cursorHalf = 0;\n        }\n        return \"variable-3\";\n      }\n\n      // bang character for !important, !default, etc.\n      if (ch === \"!\") {\n        stream.next();\n        if(!stream.peek()){\n          state.cursorHalf = 0;\n        }\n        return stream.match(/^[\\w]+/) ? \"keyword\": \"operator\";\n      }\n\n      if (stream.match(opRegexp)){\n        if(!stream.peek()){\n          state.cursorHalf = 0;\n        }\n        return \"operator\";\n      }\n\n      // attributes\n      if (stream.eatWhile(/[\\w-]/)) {\n        if(!stream.peek()){\n          state.cursorHalf = 0;\n        }\n        return \"attribute\";\n      }\n\n      //stream.eatSpace();\n      if(!stream.peek()){\n        state.cursorHalf = 0;\n        return null;\n      }\n\n    } // else ends here\n\n    if (stream.match(opRegexp))\n      return \"operator\";\n\n    // If we haven't returned by now, we move 1 character\n    // and return an error\n    stream.next();\n    return null;\n  }\n\n  function tokenLexer(stream, state) {\n    if (stream.sol()) state.indentCount = 0;\n    var style = state.tokenizer(stream, state);\n    var current = stream.current();\n\n    if (current === \"@return\" || current === \"}\"){\n      dedent(state);\n    }\n\n    if (style !== null) {\n      var startOfToken = stream.pos - current.length;\n\n      var withCurrentIndent = startOfToken + (config.indentUnit * state.indentCount);\n\n      var newScopes = [];\n\n      for (var i = 0; i < state.scopes.length; i++) {\n        var scope = state.scopes[i];\n\n        if (scope.offset <= withCurrentIndent)\n          newScopes.push(scope);\n      }\n\n      state.scopes = newScopes;\n    }\n\n\n    return style;\n  }\n\n  return {\n    startState: function() {\n      return {\n        tokenizer: tokenBase,\n        scopes: [{offset: 0, type: \"sass\"}],\n        indentCount: 0,\n        cursorHalf: 0,  // cursor half tells us if cursor lies after (1)\n                        // or before (0) colon (well... more or less)\n        definedVars: [],\n        definedMixins: []\n      };\n    },\n    token: function(stream, state) {\n      var style = tokenLexer(stream, state);\n\n      state.lastToken = { style: style, content: stream.current() };\n\n      return style;\n    },\n\n    indent: function(state) {\n      return state.scopes[0].offset;\n    }\n  };\n});\n\nCodeMirror.defineMIME(\"text/x-sass\", \"sass\");\n\n});\n"]}